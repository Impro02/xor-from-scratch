# Neural Network XOR Example

This project demonstrates how to create a neural network from scratch to fit the XOR logic gate in multiple languages.

Please refer to detailed README files in the `cpp` and `python` folders.

## Explanation

Both implementations create a simple neural network to fit the XOR logic gate. The network consists of:

1. An input layer with 2 neurons.
2. A hidden layer with 3 neurons and a Tanh activation function.
3. An output layer with 1 neuron and a Tanh activation function.
4. The network is trained using Mean Squared Error (MSE) as the loss function.
